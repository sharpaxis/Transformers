{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b525a0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attention func, Attentionhead and Mutilhead attention\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bbbbd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_attention(Q,K,V,mask=None):\n",
    "    #Query key dot product \n",
    "    q_k = torch.bmm(Q,K.mT)\n",
    "    #d_k for scaling\n",
    "    d_k = torch.tensor(K.size(-1),dtype=torch.float32)\n",
    "    scaled_qk = q_k/torch.sqrt(d_k)\n",
    "    #apply mask before softmax\n",
    "    if mask is not None:\n",
    "        scaled_qk = scaled_qk.masked_fill(mask==0,-1e9)\n",
    "    #softmax\n",
    "    soft_q_k = F.softmax(scaled_qk,dim=1)\n",
    "    #multiply weights with values\n",
    "    w_v = torch.bmm(soft_q_k,V)\n",
    "    return w_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4146f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self,embedding_dim,head_dim):\n",
    "        super(AttentionHead,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.head_dim = head_dim\n",
    "        self.Q = nn.Linear(embedding_dim,head_dim)\n",
    "        self.K = nn.Linear(embedding_dim,head_dim)\n",
    "        self.V = nn.Linear(embedding_dim,head_dim)\n",
    "    def forward(self,x,mask=None):\n",
    "        q = self.Q(x)\n",
    "        k = self.K(x)\n",
    "        v = self.V(x)\n",
    "        attention = scaled_dot_attention(q,k,v,mask)\n",
    "        return attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3be0379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMultiHeadAttention(nn.Module):\n",
    "    def __init__(self,embedding_dim,num_heads):\n",
    "        super(MaskedMultiHeadAttention,self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.head_dim = embedding_dim//num_heads\n",
    "        self.heads = nn.ModuleList([AttentionHead(self.embedding_dim,self.head_dim) for _ in range(self.num_heads)])\n",
    "        self.Wo = nn.Linear(embedding_dim,embedding_dim)\n",
    "    def forward(self,x,mask=None):\n",
    "        scores = []\n",
    "        for head in self.heads:\n",
    "            scores.append(head(x,mask))\n",
    "        scores = torch.cat(scores,2)\n",
    "        attention_representation = self.Wo(scores)\n",
    "        return attention_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4ca0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttentionHead(nn.Module):\n",
    "    def __init__(self,embedding_dim,head_dim):\n",
    "        super(CrossAttentionHead,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.head_dim = head_dim\n",
    "        self.Q = nn.Linear(embedding_dim,head_dim)\n",
    "        self.K = nn.Linear(embedding_dim,head_dim)\n",
    "        self.V = nn.Linear(embedding_dim,head_dim)\n",
    "    def forward(self,x_in,x_out,mask=None):\n",
    "        q = self.Q(x_out)\n",
    "        k = self.K(x_in)\n",
    "        v = self.V(x_in)\n",
    "        attention = scaled_dot_attention(q,k,v,mask)\n",
    "        return attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a357898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self,embedding_dim,num_heads):\n",
    "        super(CrossAttention,self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.head_dim = embedding_dim//num_heads\n",
    "        self.heads = nn.ModuleList([CrossAttentionHead(self.embedding_dim,self.head_dim) for _ in range(self.num_heads)])\n",
    "        self.Wo = nn.Linear(embedding_dim,embedding_dim)\n",
    "    def forward(self,x_in,x_out,mask=None):\n",
    "        scores = []\n",
    "        for head in self.heads:\n",
    "            scores.append(head(x_in,x_out,mask))\n",
    "        scores = torch.cat(scores,2)\n",
    "        attention_representation = self.Wo(scores)\n",
    "        return attention_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366dcaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self,embedding_dim,p=0.3):\n",
    "        super(FeedForwardNetwork,self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.d_ff = embedding_dim*4\n",
    "        self.dropout = nn.Dropout(p)\n",
    "        self.linear1 = nn.Linear(embedding_dim,self.d_ff)\n",
    "        self.linear2 = nn.Linear(self.d_ff,embedding_dim)\n",
    "    def forward(self,x):\n",
    "        x = self.linear1(x)\n",
    "        x = F.gelu(self.dropout(x))\n",
    "        x = self.linear2(x)\n",
    "        return x       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ee7949",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a690e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using learnable positional embedding\n",
    "class PosEmbedding(nn.Module):\n",
    "    def __init__(self,vocab_size,max_position,hidden_dim,p=0.2):\n",
    "        super(PosEmbedding,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocab_size,self.hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_position,self.hidden_dim)\n",
    "        self.layernorm = nn.LayerNorm(hidden_dim)\n",
    "    def forward(self,input_ids):\n",
    "        seq_len = len(input_ids)\n",
    "        positions = torch.arange(0, seq_len, dtype=torch.long).unsqueeze(0)\n",
    "        pos_emb = self.pos_embedding(positions)\n",
    "        token_emb = self.embedding(input_ids)\n",
    "        emb = self.layernorm(token_emb+pos_emb)\n",
    "        return emb   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fd8c62",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3561d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using post layer norm\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,hidden_dim,num_heads):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.feedforward = FeedForwardNetwork(hidden_dim)\n",
    "        self.maskedmultihead = MaskedMultiHeadAttention(hidden_dim,num_heads)\n",
    "        self.multiheadcross = CrossAttention(hidden_dim,num_heads)\n",
    "        self.layernorm_maskedattention = nn.LayerNorm(hidden_dim)\n",
    "        self.layernorm_crossattention = nn.LayerNorm(hidden_dim)\n",
    "        self.layernorm_feedforward = nn.LayerNorm(hidden_dim)\n",
    "    def forward(self,emb_in,emb_out):\n",
    "        att_emb = self.maskedmultihead(emb_out)\n",
    "        emb_out = self.layernorm_maskedattention(att_emb + emb_out)\n",
    "        cross_emb = self.multiheadcross(emb_in,emb_out)\n",
    "        emb = self.layernorm_crossattention(cross_emb+emb_out)\n",
    "        emb = self.layernorm_feedforward(emb + self.feedforward(emb))\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7a9ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(10,2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "812d7462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text_in,text_out):\n",
    "    text_in = '[CLS]' + text_in + '[SEP]'\n",
    "    text_out = '[CLS]' + text_out + '[SEP]'\n",
    "    input_ids = [vocab.get(token,vocab['[UNK]']) for token in text_in.lower().split()]\n",
    "    out_ids = [vocab.get(token,vocab['[UNK]']) for token in text_out.lower().split()]\n",
    "    emb_in = embedding_layer(torch.tensor(input_ids))\n",
    "    emb_out = embedding_layer(torch.tensor(out_ids))\n",
    "    final = decoder(emb_in,emb_out)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479edc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'[MASK]':0,'[PAD]':1,'[SEP]':2,'[CLS]':3,'hello':4,'how':5,'are':6,'you':7,'adi':8,'i':9,'am':10,'[UNK]':11,',':12,'.':13,'?':14}\n",
    "vocab_size = len(vocab)\n",
    "hidden_dim = 10\n",
    "max_pos = 10\n",
    "embedding_layer = PosEmbedding(vocab_size,max_pos,hidden_dim)\n",
    "decoder = Decoder(10,2)\n",
    "text = \"Hello how are you ? I Am Adi\"\n",
    "text2 = \"are you adi?\"\n",
    "text_embeddings = process_text(text,text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd07999d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2091,  1.9794,  0.7957, -0.6276,  0.5124,  1.0756, -0.0389,\n",
       "          -0.8240, -0.5982, -1.0654],\n",
       "         [ 1.8392, -1.0725,  0.1597,  0.3007, -1.6764,  1.2864,  0.2637,\n",
       "          -0.2638,  0.0266, -0.8636],\n",
       "         [-1.9224,  1.4546,  0.7938,  0.7233,  0.7088, -0.2325, -0.2617,\n",
       "           0.3881, -0.1569, -1.4950]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "244fe7e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iinfo(min=-9.22337e+18, max=9.22337e+18, dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.iinfo(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2caae8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "finfo(resolution=0.01, min=-3.38953e+38, max=3.38953e+38, eps=0.0078125, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=bfloat16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.finfo(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e74a97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52131437818381.000000000000000\n",
      "52226802319360.000000000000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xw/knd54pd91c7cw57n21dntvx80000gn/T/ipykernel_87411/2981044022.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(x,dtype=torch.bfloat16)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([52131437818381],dtype=torch.float64)\n",
    "print(f\"{float(x):.15f}\")\n",
    "y = torch.tensor(x,dtype=torch.bfloat16)\n",
    "print(f\"{float(y):.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "360ec2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization error: -95364500979.000000000000000\n"
     ]
    }
   ],
   "source": [
    "z = x-y\n",
    "print(f\"Quantization error: {float(z):.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e9d651c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensor_size(tensor):\n",
    "    bytes = tensor.element_size() * tensor.numel()\n",
    "    kb = bytes / 1024\n",
    "    mb = kb / 1024\n",
    "    return f\"Size: {bytes} bytes, {kb:.2f} KB, {mb:.2f} MB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "35a60a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Size: 2 bytes, 0.00 KB, 0.00 MB'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tensor_size(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3b2baf61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size : 8 bytes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Size : {x.element_size() * x.numel()} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b77e0fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size : 1 bytes\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3],dtype=torch.int8)\n",
    "print(f\"Size : {a.element_size() * a.numel()} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8d675afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size : 2 bytes\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3],dtype=torch.int16)\n",
    "print(f\"Size : {a.element_size() * a.numel()} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f9c529a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size : 4 bytes\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3],dtype=torch.int32)\n",
    "print(f\"Size : {a.element_size() * a.numel()} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f6a06634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size : 8 bytes\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([3],dtype=torch.int64)\n",
    "print(f\"Size : {a.element_size() * a.numel()} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "676caf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_fp32 = torch.randn(10000,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "6d9bba01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2567,  1.2481,  1.0715, -1.3943])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_fp32[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b229869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_fp16 = tensor_fp32.to(dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "55433d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2568,  1.2480,  1.0713, -1.3945], dtype=torch.float16)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_fp16[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fa26b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_32 = torch.dot(tensor_fp32,tensor_fp32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "293baff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_16 = torch.dot(tensor_fp16,tensor_fp16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "aea72ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10070.8564)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "baf33168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10072., dtype=torch.float16)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3607d39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1436)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.abs(mm_32-mm_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1a31e603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_32.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d3922679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm_16.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d6475959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (feedforward): FeedForwardNetwork(\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (linear1): Linear(in_features=10, out_features=40, bias=True)\n",
       "    (linear2): Linear(in_features=40, out_features=10, bias=True)\n",
       "  )\n",
       "  (maskedmultihead): MaskedMultiHeadAttention(\n",
       "    (heads): ModuleList(\n",
       "      (0-1): 2 x AttentionHead(\n",
       "        (Q): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (K): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (V): Linear(in_features=10, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (Wo): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       "  (multiheadcross): CrossAttention(\n",
       "    (heads): ModuleList(\n",
       "      (0-1): 2 x CrossAttentionHead(\n",
       "        (Q): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (K): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (V): Linear(in_features=10, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (Wo): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       "  (layernorm_maskedattention): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "  (layernorm_crossattention): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "  (layernorm_feedforward): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fd65f58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name : feedforward.linear1.weight Param : torch.float32\n",
      "Name : feedforward.linear1.bias Param : torch.float32\n",
      "Name : feedforward.linear2.weight Param : torch.float32\n",
      "Name : feedforward.linear2.bias Param : torch.float32\n",
      "Name : maskedmultihead.heads.0.Q.weight Param : torch.float32\n",
      "Name : maskedmultihead.heads.0.Q.bias Param : torch.float32\n",
      "Name : maskedmultihead.heads.0.K.weight Param : torch.float32\n",
      "Name : maskedmultihead.heads.0.K.bias Param : torch.float32\n",
      "Name : maskedmultihead.heads.0.V.weight Param : torch.float32\n",
      "Name : maskedmultihead.heads.0.V.bias Param : torch.float32\n",
      "Name : maskedmultihead.heads.1.Q.weight Param : torch.float32\n",
      "Name : maskedmultihead.heads.1.Q.bias Param : torch.float32\n",
      "Name : maskedmultihead.heads.1.K.weight Param : torch.float32\n",
      "Name : maskedmultihead.heads.1.K.bias Param : torch.float32\n",
      "Name : maskedmultihead.heads.1.V.weight Param : torch.float32\n",
      "Name : maskedmultihead.heads.1.V.bias Param : torch.float32\n",
      "Name : maskedmultihead.Wo.weight Param : torch.float32\n",
      "Name : maskedmultihead.Wo.bias Param : torch.float32\n",
      "Name : multiheadcross.heads.0.Q.weight Param : torch.float32\n",
      "Name : multiheadcross.heads.0.Q.bias Param : torch.float32\n",
      "Name : multiheadcross.heads.0.K.weight Param : torch.float32\n",
      "Name : multiheadcross.heads.0.K.bias Param : torch.float32\n",
      "Name : multiheadcross.heads.0.V.weight Param : torch.float32\n",
      "Name : multiheadcross.heads.0.V.bias Param : torch.float32\n",
      "Name : multiheadcross.heads.1.Q.weight Param : torch.float32\n",
      "Name : multiheadcross.heads.1.Q.bias Param : torch.float32\n",
      "Name : multiheadcross.heads.1.K.weight Param : torch.float32\n",
      "Name : multiheadcross.heads.1.K.bias Param : torch.float32\n",
      "Name : multiheadcross.heads.1.V.weight Param : torch.float32\n",
      "Name : multiheadcross.heads.1.V.bias Param : torch.float32\n",
      "Name : multiheadcross.Wo.weight Param : torch.float32\n",
      "Name : multiheadcross.Wo.bias Param : torch.float32\n",
      "Name : layernorm_maskedattention.weight Param : torch.float32\n",
      "Name : layernorm_maskedattention.bias Param : torch.float32\n",
      "Name : layernorm_crossattention.weight Param : torch.float32\n",
      "Name : layernorm_crossattention.bias Param : torch.float32\n",
      "Name : layernorm_feedforward.weight Param : torch.float32\n",
      "Name : layernorm_feedforward.bias Param : torch.float32\n"
     ]
    }
   ],
   "source": [
    "for name, param in decoder.named_parameters():\n",
    "    print(f\"Name : {name} Param : {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "249d58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_64 = Decoder(10,2).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f371e770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name : feedforward.linear1.weight Param : torch.float64\n",
      "Name : feedforward.linear1.bias Param : torch.float64\n",
      "Name : feedforward.linear2.weight Param : torch.float64\n",
      "Name : feedforward.linear2.bias Param : torch.float64\n",
      "Name : maskedmultihead.heads.0.Q.weight Param : torch.float64\n",
      "Name : maskedmultihead.heads.0.Q.bias Param : torch.float64\n",
      "Name : maskedmultihead.heads.0.K.weight Param : torch.float64\n",
      "Name : maskedmultihead.heads.0.K.bias Param : torch.float64\n",
      "Name : maskedmultihead.heads.0.V.weight Param : torch.float64\n",
      "Name : maskedmultihead.heads.0.V.bias Param : torch.float64\n",
      "Name : maskedmultihead.heads.1.Q.weight Param : torch.float64\n",
      "Name : maskedmultihead.heads.1.Q.bias Param : torch.float64\n",
      "Name : maskedmultihead.heads.1.K.weight Param : torch.float64\n",
      "Name : maskedmultihead.heads.1.K.bias Param : torch.float64\n",
      "Name : maskedmultihead.heads.1.V.weight Param : torch.float64\n",
      "Name : maskedmultihead.heads.1.V.bias Param : torch.float64\n",
      "Name : maskedmultihead.Wo.weight Param : torch.float64\n",
      "Name : maskedmultihead.Wo.bias Param : torch.float64\n",
      "Name : multiheadcross.heads.0.Q.weight Param : torch.float64\n",
      "Name : multiheadcross.heads.0.Q.bias Param : torch.float64\n",
      "Name : multiheadcross.heads.0.K.weight Param : torch.float64\n",
      "Name : multiheadcross.heads.0.K.bias Param : torch.float64\n",
      "Name : multiheadcross.heads.0.V.weight Param : torch.float64\n",
      "Name : multiheadcross.heads.0.V.bias Param : torch.float64\n",
      "Name : multiheadcross.heads.1.Q.weight Param : torch.float64\n",
      "Name : multiheadcross.heads.1.Q.bias Param : torch.float64\n",
      "Name : multiheadcross.heads.1.K.weight Param : torch.float64\n",
      "Name : multiheadcross.heads.1.K.bias Param : torch.float64\n",
      "Name : multiheadcross.heads.1.V.weight Param : torch.float64\n",
      "Name : multiheadcross.heads.1.V.bias Param : torch.float64\n",
      "Name : multiheadcross.Wo.weight Param : torch.float64\n",
      "Name : multiheadcross.Wo.bias Param : torch.float64\n",
      "Name : layernorm_maskedattention.weight Param : torch.float64\n",
      "Name : layernorm_maskedattention.bias Param : torch.float64\n",
      "Name : layernorm_crossattention.weight Param : torch.float64\n",
      "Name : layernorm_crossattention.bias Param : torch.float64\n",
      "Name : layernorm_feedforward.weight Param : torch.float64\n",
      "Name : layernorm_feedforward.bias Param : torch.float64\n"
     ]
    }
   ],
   "source": [
    "for name, param in decoder_64.named_parameters():\n",
    "    print(f\"Name : {name} Param : {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "264e95da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name : feedforward.linear1.weight Param : torch.float16\n",
      "Name : feedforward.linear1.bias Param : torch.float16\n",
      "Name : feedforward.linear2.weight Param : torch.float16\n",
      "Name : feedforward.linear2.bias Param : torch.float16\n",
      "Name : maskedmultihead.heads.0.Q.weight Param : torch.float16\n",
      "Name : maskedmultihead.heads.0.Q.bias Param : torch.float16\n",
      "Name : maskedmultihead.heads.0.K.weight Param : torch.float16\n",
      "Name : maskedmultihead.heads.0.K.bias Param : torch.float16\n",
      "Name : maskedmultihead.heads.0.V.weight Param : torch.float16\n",
      "Name : maskedmultihead.heads.0.V.bias Param : torch.float16\n",
      "Name : maskedmultihead.heads.1.Q.weight Param : torch.float16\n",
      "Name : maskedmultihead.heads.1.Q.bias Param : torch.float16\n",
      "Name : maskedmultihead.heads.1.K.weight Param : torch.float16\n",
      "Name : maskedmultihead.heads.1.K.bias Param : torch.float16\n",
      "Name : maskedmultihead.heads.1.V.weight Param : torch.float16\n",
      "Name : maskedmultihead.heads.1.V.bias Param : torch.float16\n",
      "Name : maskedmultihead.Wo.weight Param : torch.float16\n",
      "Name : maskedmultihead.Wo.bias Param : torch.float16\n",
      "Name : multiheadcross.heads.0.Q.weight Param : torch.float16\n",
      "Name : multiheadcross.heads.0.Q.bias Param : torch.float16\n",
      "Name : multiheadcross.heads.0.K.weight Param : torch.float16\n",
      "Name : multiheadcross.heads.0.K.bias Param : torch.float16\n",
      "Name : multiheadcross.heads.0.V.weight Param : torch.float16\n",
      "Name : multiheadcross.heads.0.V.bias Param : torch.float16\n",
      "Name : multiheadcross.heads.1.Q.weight Param : torch.float16\n",
      "Name : multiheadcross.heads.1.Q.bias Param : torch.float16\n",
      "Name : multiheadcross.heads.1.K.weight Param : torch.float16\n",
      "Name : multiheadcross.heads.1.K.bias Param : torch.float16\n",
      "Name : multiheadcross.heads.1.V.weight Param : torch.float16\n",
      "Name : multiheadcross.heads.1.V.bias Param : torch.float16\n",
      "Name : multiheadcross.Wo.weight Param : torch.float16\n",
      "Name : multiheadcross.Wo.bias Param : torch.float16\n",
      "Name : layernorm_maskedattention.weight Param : torch.float16\n",
      "Name : layernorm_maskedattention.bias Param : torch.float16\n",
      "Name : layernorm_crossattention.weight Param : torch.float16\n",
      "Name : layernorm_crossattention.bias Param : torch.float16\n",
      "Name : layernorm_feedforward.weight Param : torch.float16\n",
      "Name : layernorm_feedforward.bias Param : torch.float16\n"
     ]
    }
   ],
   "source": [
    "decoder_16 = Decoder(10,2).half()\n",
    "for name, param in decoder_16.named_parameters():\n",
    "    print(f\"Name : {name} Param : {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f65bd3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (feedforward): FeedForwardNetwork(\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (linear1): Linear(in_features=10, out_features=40, bias=True)\n",
       "    (linear2): Linear(in_features=40, out_features=10, bias=True)\n",
       "  )\n",
       "  (maskedmultihead): MaskedMultiHeadAttention(\n",
       "    (heads): ModuleList(\n",
       "      (0-1): 2 x AttentionHead(\n",
       "        (Q): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (K): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (V): Linear(in_features=10, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (Wo): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       "  (multiheadcross): CrossAttention(\n",
       "    (heads): ModuleList(\n",
       "      (0-1): 2 x CrossAttentionHead(\n",
       "        (Q): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (K): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (V): Linear(in_features=10, out_features=5, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (Wo): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       "  (layernorm_maskedattention): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "  (layernorm_crossattention): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       "  (layernorm_feedforward): LayerNorm((10,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ff5d66c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name : feedforward.linear1.weight Param : torch.bfloat16\n",
      "Name : feedforward.linear1.bias Param : torch.bfloat16\n",
      "Name : feedforward.linear2.weight Param : torch.bfloat16\n",
      "Name : feedforward.linear2.bias Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.0.Q.weight Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.0.Q.bias Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.0.K.weight Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.0.K.bias Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.0.V.weight Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.0.V.bias Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.1.Q.weight Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.1.Q.bias Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.1.K.weight Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.1.K.bias Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.1.V.weight Param : torch.bfloat16\n",
      "Name : maskedmultihead.heads.1.V.bias Param : torch.bfloat16\n",
      "Name : maskedmultihead.Wo.weight Param : torch.bfloat16\n",
      "Name : maskedmultihead.Wo.bias Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.0.Q.weight Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.0.Q.bias Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.0.K.weight Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.0.K.bias Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.0.V.weight Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.0.V.bias Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.1.Q.weight Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.1.Q.bias Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.1.K.weight Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.1.K.bias Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.1.V.weight Param : torch.bfloat16\n",
      "Name : multiheadcross.heads.1.V.bias Param : torch.bfloat16\n",
      "Name : multiheadcross.Wo.weight Param : torch.bfloat16\n",
      "Name : multiheadcross.Wo.bias Param : torch.bfloat16\n",
      "Name : layernorm_maskedattention.weight Param : torch.bfloat16\n",
      "Name : layernorm_maskedattention.bias Param : torch.bfloat16\n",
      "Name : layernorm_crossattention.weight Param : torch.bfloat16\n",
      "Name : layernorm_crossattention.bias Param : torch.bfloat16\n",
      "Name : layernorm_feedforward.weight Param : torch.bfloat16\n",
      "Name : layernorm_feedforward.bias Param : torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "decoder_bf16 = Decoder(10,2).bfloat16()\n",
    "for name, param in decoder_bf16.named_parameters():\n",
    "    print(f\"Name : {name} Param : {param.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc47f8c",
   "metadata": {},
   "source": [
    "### diff in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f8b24f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text_in,text_out):\n",
    "    text_in = '[CLS]' + text_in + '[SEP]'\n",
    "    text_out = '[CLS]' + text_out + '[SEP]'\n",
    "    input_ids = [vocab.get(token,vocab['[UNK]']) for token in text_in.lower().split()]\n",
    "    out_ids = [vocab.get(token,vocab['[UNK]']) for token in text_out.lower().split()]\n",
    "    emb_in = embedding_layer(torch.tensor(input_ids))\n",
    "    emb_out = embedding_layer(torch.tensor(out_ids))\n",
    "    return emb_in,emb_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "15920236",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_in,emb_out = process_text(text,text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8bd4b9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000169038773\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(1000):\n",
    "    start = time.time()\n",
    "    out = decoder(emb_in,emb_out)\n",
    "    end = time.time()\n",
    "    total = end-start\n",
    "print(f\"{total/1000:.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8c8d2bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_in = emb_in.to(torch.float64)\n",
    "emb_out = emb_out.to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "72cb7725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000000184059143\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(1000):\n",
    "    start = time.time()\n",
    "    out = decoder_64(emb_in,emb_out)\n",
    "    end = time.time()\n",
    "    total = end-start\n",
    "print(f\"{total/1000:.15f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f3fc946b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.311302099999999e-08"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.000000182151794 - 0.000000169038773"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f03dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
